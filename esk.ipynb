{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import re\n",
    "from bs4 import BeautifulSoup as bs4\n",
    "from IPython.display import display, HTML\n",
    "import os\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_id = os.environ.get(\"DEVIANTART_CLIENT_ID\")\n",
    "client_secret = os.environ.get(\"DEVIANTART_CLIENT_SECRET\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_request = requests.post(\"https://www.deviantart.com/oauth2/token\", params= {\n",
    "    \"client_id\": client_id,\n",
    "    \"client_secret\": client_secret,\n",
    "    \"grant_type\": \"client_credentials\"\n",
    "} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = token_request.json()[\"access_token\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "offset = 0\n",
    "limit = 24\n",
    "esk_request = requests.get(\"https://www.deviantart.com/api/v1/oauth2/gallery/all\", \n",
    "headers={\n",
    "    'Authorization': 'Bearer {}'.format(token)\n",
    "    }, \n",
    "    params= {\n",
    "    \"username\": \"esk-masterlist\",\n",
    "    \"offset\": offset,\n",
    "    \"limit\": limit\n",
    "}).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "esk_requests = [esk_request[\"results\"]]\n",
    "while esk_request[\"has_more\"]:\n",
    "    offset += limit\n",
    "    esk_request = requests.get(\"https://www.deviantart.com/api/v1/oauth2/gallery/all\", \n",
    "        headers={\n",
    "            'Authorization': 'Bearer {}'.format(token)\n",
    "            }, \n",
    "            params= {\n",
    "            \"username\": \"esk-masterlist\",\n",
    "            \"offset\": offset,\n",
    "            \"limit\": limit\n",
    "        }).json()\n",
    "    esk_requests.append(esk_request[\"results\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deviation_ids = [{\"deviationid\": esk[\"deviationid\"], \"publication date\": dt.datetime.fromtimestamp(int(esk[\"published_time\"]))} for esks in esk_requests for esk in esks]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_index = 0\n",
    "end_index = 50\n",
    "esk_metadata_request = requests.post(\"https://www.deviantart.com/api/v1/oauth2/deviation/metadata\", \n",
    "    data={\n",
    "        \"deviationids[]\": [entry[\"deviationid\"] for entry in deviation_ids[start_index:end_index]]\n",
    "    },\n",
    "    headers={\n",
    "        'Authorization': 'Bearer {}'.format(token)\n",
    "    }).json()[\"metadata\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "esk_metadata = [esk_metadata_request]\n",
    "while end_index < len(deviation_ids):\n",
    "    start_index += 50\n",
    "    end_index += 50\n",
    "    if end_index > len(deviation_ids):\n",
    "        end_index = len(deviation_ids)\n",
    "    esk_metadata_request = requests.post(\"https://www.deviantart.com/api/v1/oauth2/deviation/metadata\", \n",
    "    data={\n",
    "        \"deviationids[]\": [entry[\"deviationid\"] for entry in deviation_ids[start_index:end_index]]\n",
    "    },\n",
    "    headers={\n",
    "        'Authorization': 'Bearer {}'.format(token)\n",
    "    }).json()[\"metadata\"]\n",
    "    esk_metadata.append(esk_metadata_request)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def owner_count_from_description(owner_history):\n",
    "    owner_count = 0\n",
    "    owner_history_list = str.split(owner_history, \"|\")\n",
    "    while str.isspace(owner_history_list[0]) or len(owner_history_list[0]) == 0 or owner_history_list[0].strip() == 'reserved':\n",
    "        owner_history_list.pop(0)\n",
    "        if len(owner_history_list) == 0:\n",
    "            return 0\n",
    "    if owner_history_list[0].strip() in ['staff reward for', 'claimed from', 'created via', 'staff reward', 'purchased', 'won via', 'created via transformation by', 'MYO by', 'won via\\\\xa0', 'created via\\\\xa0', 'staff reward for\\\\xa0', 'claimed from\\\\xa0', 'semi-custom', 'purchased\\\\xa0', 'purchased MYO', 'rare MYO purchased by', 'ThoseWhoWentMissing', '\\\\xa0', 'purchased MYO slot by', 'purchased by', 'purchased MYO slot', 'staff reward claimed by', 'Common MYO purchased by', 'common MYO purchased by', 'uncommon MYO purchased by', 'A Walk in the Woods', 'MYO purchased', 'custom purchased by', 'Won in FTO raffle', 'prize for winning the', 'purchased MYO by', 'obtained via transformation by', 'Won in holiday raffle', \"Purchased\", \"claimed via\"]:\n",
    "        owner_count += 1\n",
    "    owner_history = \"|\" + owner_history + \"|\"\n",
    "    owner_count += len(re.findall(r\"\\|[^|]*\\s+to\\s+[^|]*\\||\\|\\s*to\\s*\\|\", owner_history))\n",
    "    return owner_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def owner_count_from_web_response(raw_esk_record):\n",
    "    parsed_html = bs4(raw_esk_record[\"description\"])\n",
    "    owner_history = parsed_html.body.select_one('div > b:-soup-contains(\"owner history\")', class_=\"legacy-journal\")\n",
    "    try:\n",
    "        owner_history = owner_history.find_next_sibling(\"sub\")\n",
    "        owner_history = owner_history.get_text(\"|\", strip=False) \n",
    "        owner_history = re.sub('\\\\xa0', \" \", owner_history)\n",
    "    except:\n",
    "        owner_history = parsed_html.body.select_one('div > b', class_=\"legacy-journal\").parent.parent.get_text(\"|\", strip=True)\n",
    "        owner_history = re.sub('\\\\xa0', \" \", owner_history)\n",
    "        owner_history = re.sub(r'.*owner history\\s*', \"\", owner_history)\n",
    "        owner_history = re.sub(r'Esk are a closed species.*', \"\", owner_history)\n",
    "    owner_count = owner_count_from_description(owner_history)\n",
    "    if owner_count == 0:\n",
    "        owner_history = parsed_html.body.select_one('div > b', class_=\"legacy-journal\").parent.parent.parent.get_text(\"|\", strip=True)\n",
    "        owner_history = re.sub('\\\\xa0', \" \", owner_history)\n",
    "        owner_history = re.sub(r'.*owner history\\s*', \"\", owner_history)\n",
    "        owner_history = re.sub(r'Esk are a closed species.*', \"\", owner_history)\n",
    "        owner_count = owner_count_from_description(owner_history)\n",
    "    return owner_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_category(description, category, category_list):\n",
    "    try:\n",
    "        category_index = description.index(category)\n",
    "        category_list = set(category_list)\n",
    "        next_category = next((ele for ele in description[category_index + 1:] if ele in category_list), None)\n",
    "        if next_category != None:\n",
    "            try:\n",
    "                next_category_index = description.index(next_category)\n",
    "            except ValueError:\n",
    "                return 'NA'\n",
    "            category_text = \" \".join(description[category_index+1:next_category_index])    \n",
    "        else:\n",
    "            category_text = \" \".join(description[category_index+1:])\n",
    "            \n",
    "        category_text = re.sub(r'[\\.\\(]$', \"\", category_text)\n",
    "        category_text = category_text.strip()\n",
    "        return category_text\n",
    "    except ValueError:\n",
    "        return 'NA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def esk_record_from_web_response(raw_esk_record):\n",
    "    parsed_html = bs4(raw_esk_record[\"description\"])\n",
    "    description = parsed_html.body.select_one('div > b', class_=\"legacy-journal\").parent.parent.get_text(\"|\", strip=True)\n",
    "    description = re.sub(r'ownership.*', \"\", description)\n",
    "    description = re.sub(r'\\* this pre-arpg mutation is no longer allowed for new esk', \"\", description)\n",
    "    description = re.sub(r'Esk are a closed species.*', \"\", description)\n",
    "    description = re.sub(r'\\([^\\)]*\\)', \"\", description)\n",
    "    description = re.sub('\\\\xa0', \" \", description)\n",
    "    description = re.sub(r'nature feature\\s+', \"nature features\", description)\n",
    "    description = re.sub(r'mutation(?!s)', \"mutations\", description)\n",
    "    description = re.sub(r'accessory', \"accessories\", description)\n",
    "    description = re.sub(r'elemental(?!s)', \"elementals\", description)\n",
    "    description = re.sub(r'familiar(?!s)', \"familiars\", description)\n",
    "    description = re.sub(r'enchantment(?!s)', \"enchantments\", description)\n",
    "    description = re.sub(r'blessing(?!s)', \"blessings\", description)\n",
    "    description = re.sub(r'curse(?!s)', \"curses\", description)\n",
    "    description = re.sub(r'morphs', \"morph\", description)\n",
    "    description = re.sub('designers', \"designer\", description)\n",
    "    description = str.split(description, \"|\")\n",
    "    category_list = [\"origin\", \"nature\", \"boundary\", \"size\", \"species\", \"collection\", \"designer\", \"uncommon traits\", \"rare traits\", \"unique traits\", \"nature features\", \"mutations\", \"morph\", \"original form\", \"accessories\", \"familiars\", \"enchantments\", \"elementals\", \"TF rewards\", \"blessings\", \"curses\"]\n",
    "    for category in category_list:\n",
    "        raw_esk_record[category] = get_category(description, category, category_list)\n",
    "    raw_esk_record[\"owner count\"] = owner_count_from_web_response(raw_esk_record)\n",
    "    raw_esk_record.pop(\"size\", None)\n",
    "    raw_esk_record.pop(\"designer\", None)\n",
    "    raw_esk_record.pop(\"description\", None)\n",
    "    raw_esk_record.pop(\"TF rewards\", None)\n",
    "    raw_esk_record.pop(\"blessings\", None)\n",
    "    raw_esk_record.pop(\"curses\", None)\n",
    "    return raw_esk_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "esk_descriptions = [{\"deviationid\": esk[\"deviationid\"], \"title\": esk[\"title\"], \"description\": esk[\"description\"]} for esks in esk_metadata for esk in esks if (re.fullmatch( r\"\\d{3,4}\", esk[\"title\"]) != None)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|gifted via|wellsprings|by|CelestialWolf66|\n",
      "|gifted via|wellsprings|by|somnum19|\n",
      "|(method of obtaining) by @|\n",
      "\n",
      "nix gefunden!\n",
      "|\n",
      "\n",
      "\n",
      "nix gefunden!\n",
      "|\n",
      "\n",
      "|\n",
      "|(method of obtaining) by @|\n",
      "|(method of obtaining) by @|\n",
      "|(method of obtaining) by @|\n",
      "|???|\n",
      "|gifted via|wellsprings|by|sad-poptart|\n",
      "|???|\n",
      "|witherlings|gifted to|senka-shadow|senka-shadow|resold to|Keeveehart|Keeveehart|resold to|Casuke|Casuke|resold to|KettleGhoul|KettleGhoul|account transfer to|yokovi|\n",
      "|Yunonia|purchased|for|manaberry|\n",
      "|corowne|purchased|for @|jaywalkings|jaywalkings|swapped to|Eldritch-Aberrance|\n",
      "origin|trespasser .|nature|vain .|boundary|coastline .|size|spindly|species|esk|.|collection|guest designs .|designer|darkmoondancer|uncommon traits|none|rare traits|none|nature feature|feather reed grass|accessories|sea glass necklace (sea glass and fine woven driftwood)|enchantment|commanding aura (crown)\n",
      "|Verlidaine|purchased directly from|witherlings|\n",
      "|MYO gifted to|Lyrak|\n",
      "|wish granted at|Wellsprings|for|SkellumSketch|\n",
      "|Jei9|sold (|guest design|) to|Friiha|\n",
      "|created via granted|Wellsprings wish|by|bloodbarf|\n",
      "|ava-lees|transformation|ava-lees|swapped to|AlsaresLynx|\n",
      "|(method of obtaining) by @|\n",
      "|(method of obtaining) by @|\n",
      "|obtained via|transformation|by|aHorseForEverySeason|for|ehhhart|\n",
      "|created by|witherlings|\n",
      "|transformation|by|Kyuuyula|\n",
      "\n",
      "nix gefunden!\n",
      "|reserved|\n",
      "\n",
      "\n",
      "nix gefunden!\n",
      "|reserved|\n",
      "\n",
      "|reserved|\n"
     ]
    }
   ],
   "source": [
    "esk_list = []\n",
    "for esk in esk_descriptions:\n",
    "    cleaned = esk_record_from_web_response(esk)\n",
    "    if cleaned != None:\n",
    "        esk_list.append(cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'origin'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexes/base.py:3800\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3799\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3800\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3801\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/_libs/index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'origin'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [302], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m deviation_id_frame \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(deviation_ids)\n\u001b[1;32m      3\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mmerge(df, deviation_id_frame, on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeviationid\u001b[39m\u001b[38;5;124m\"\u001b[39m, how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minner\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m df \u001b[38;5;241m=\u001b[39m df[df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morigin\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      5\u001b[0m df \u001b[38;5;241m=\u001b[39m df[df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morigin\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m???\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/frame.py:3805\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3803\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   3804\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3805\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   3806\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3807\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexes/base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3800\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3801\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3802\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3804\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3805\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3806\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3807\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'origin'"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(esk_list)\n",
    "deviation_id_frame = pd.DataFrame(deviation_ids)\n",
    "df = pd.merge(df, deviation_id_frame, on=\"deviationid\", how=\"inner\")\n",
    "df = df[df[\"origin\"] != \"-\"]\n",
    "df = df[df[\"origin\"] != \"???\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_biome_from_comments(deviationid):\n",
    "    global df\n",
    "    try:\n",
    "        esk_comment_metadata = requests.get(f\"https://www.deviantart.com/api/v1/oauth2/comments/deviation/{deviationid}\", \n",
    "            headers={\n",
    "                'Authorization': 'Bearer {}'.format(token)\n",
    "            },\n",
    "            params={\n",
    "                \"maxdepth\": 2\n",
    "            }).json()[\"thread\"]\n",
    "        if len(esk_comment_metadata) > 0:\n",
    "            parent_comment_id = ''\n",
    "            for comment in esk_comment_metadata:\n",
    "                if comment[\"parentid\"] == None and comment[\"user\"][\"username\"] == \"Esk-Masterlist\":\n",
    "                    parent_comment_id = comment[\"commentid\"]\n",
    "                    break\n",
    "            if len(parent_comment_id) == 0:\n",
    "                raise ValueError(\"No Esk-Masterlist comment found\")\n",
    "        else:\n",
    "             raise ValueError(\"No comments found\")\n",
    "        biome_comment = ''\n",
    "        for comment in esk_comment_metadata:\n",
    "            if comment[\"parentid\"] == parent_comment_id and comment[\"user\"][\"username\"] == \"Esk-Masterlist\":\n",
    "                biome_comment = comment[\"body\"]\n",
    "                break\n",
    "        if len(biome_comment) == 0:\n",
    "                raise ValueError(\"No reply to biome comment found\")    \n",
    "        comment_soup = bs4(biome_comment)\n",
    "        comment = comment_soup.body.find(\"img\")[\"alt\"]\n",
    "        comment = re.sub(\" by Esk-Masterlist\", \"\", comment)\n",
    "        df.loc[df[\"deviationid\"] == deviationid,\"biome\"] = comment\n",
    "        return comment\n",
    "    except ValueError as v:\n",
    "        df.loc[df[\"deviationid\"] == deviationid,\"biome\"] = \"NA\"\n",
    "        return v\n",
    "    except KeyError as k:\n",
    "        df.loc[df[\"deviationid\"] == deviationid,\"biome\"] = \"NA\"\n",
    "        return k\n",
    "    except Exception as e:\n",
    "        df.loc[df[\"deviationid\"] == deviationid,\"biome\"] = \"NA\"\n",
    "        return e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runner():\n",
    "    global df\n",
    "    threads= []\n",
    "    with ThreadPoolExecutor(max_workers=24) as executor:\n",
    "        for deviationid in df[\"deviationid\"]:\n",
    "            threads.append(executor.submit(get_biome_from_comments, deviationid))\n",
    "        \"\"\" for task in as_completed(threads):\n",
    "            print(task.result()) \"\"\" \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"esks_asgoodasitgets.csv\", \"w\") as csv_file:\n",
    "    df.to_csv(csv_file, encoding='utf-8', sep=';')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
