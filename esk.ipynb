{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import re\n",
    "from bs4 import BeautifulSoup as bs4\n",
    "from IPython.display import display, HTML\n",
    "import os\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_id = os.environ.get(\"DEVIANTART_CLIENT_ID\")\n",
    "client_secret = os.environ.get(\"DEVIANTART_CLIENT_SECRET\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_request = requests.post(\"https://www.deviantart.com/oauth2/token\", params= {\n",
    "    \"client_id\": client_id,\n",
    "    \"client_secret\": client_secret,\n",
    "    \"grant_type\": \"client_credentials\"\n",
    "} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = token_request.json()[\"access_token\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "offset = 0\n",
    "limit = 24\n",
    "esk_request = requests.get(\"https://www.deviantart.com/api/v1/oauth2/gallery/all\", \n",
    "headers={\n",
    "    'Authorization': 'Bearer {}'.format(token)\n",
    "    }, \n",
    "    params= {\n",
    "    \"username\": \"esk-masterlist\",\n",
    "    \"offset\": offset,\n",
    "    \"limit\": limit\n",
    "}).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "esk_requests = [esk_request[\"results\"]]\n",
    "while esk_request[\"has_more\"]:\n",
    "    offset += limit\n",
    "    esk_request = requests.get(\"https://www.deviantart.com/api/v1/oauth2/gallery/all\", \n",
    "        headers={\n",
    "            'Authorization': 'Bearer {}'.format(token)\n",
    "            }, \n",
    "            params= {\n",
    "            \"username\": \"esk-masterlist\",\n",
    "            \"offset\": offset,\n",
    "            \"limit\": limit\n",
    "        }).json()\n",
    "    esk_requests.append(esk_request[\"results\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "deviation_ids = [{\"deviationid\": esk[\"deviationid\"], \"publication date\": dt.datetime.fromtimestamp(int(esk[\"published_time\"]))} for esks in esk_requests for esk in esks]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_index = 0\n",
    "end_index = 50\n",
    "esk_metadata_request = requests.post(\"https://www.deviantart.com/api/v1/oauth2/deviation/metadata\", \n",
    "    data={\n",
    "        \"deviationids[]\": [entry[\"deviationid\"] for entry in deviation_ids[start_index:end_index]]\n",
    "    },\n",
    "    headers={\n",
    "        'Authorization': 'Bearer {}'.format(token)\n",
    "    }).json()[\"metadata\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "esk_metadata = [esk_metadata_request]\n",
    "while end_index < len(deviation_ids):\n",
    "    start_index += 50\n",
    "    end_index += 50\n",
    "    if end_index > len(deviation_ids):\n",
    "        end_index = len(deviation_ids)\n",
    "    esk_metadata_request = requests.post(\"https://www.deviantart.com/api/v1/oauth2/deviation/metadata\", \n",
    "    data={\n",
    "        \"deviationids[]\": [entry[\"deviationid\"] for entry in deviation_ids[start_index:end_index]]\n",
    "    },\n",
    "    headers={\n",
    "        'Authorization': 'Bearer {}'.format(token)\n",
    "    }).json()[\"metadata\"]\n",
    "    esk_metadata.append(esk_metadata_request)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "def owner_count_from_description(owner_history):\n",
    "    owner_count = 0\n",
    "    owner_history_list = str.split(owner_history, \"|\")\n",
    "    while str.isspace(owner_history_list[0]) or len(owner_history_list[0]) == 0 or owner_history_list[0].strip() == 'reserved':\n",
    "        owner_history_list.pop(0)\n",
    "        if len(owner_history_list) == 0:\n",
    "            return 0\n",
    "    if owner_history_list[0].strip() in ['staff reward for', 'claimed from', 'created via', 'staff reward', 'purchased', 'won via', 'created via transformation by', 'MYO by', 'won via\\\\xa0', 'created via\\\\xa0', 'staff reward for\\\\xa0', 'claimed from\\\\xa0', 'semi-custom', 'purchased\\\\xa0', 'purchased MYO', 'rare MYO purchased by', 'ThoseWhoWentMissing', '\\\\xa0', 'purchased MYO slot by', 'purchased by', 'purchased MYO slot', 'staff reward claimed by', 'Common MYO purchased by', 'common MYO purchased by', 'uncommon MYO purchased by', 'A Walk in the Woods', 'MYO purchased', 'custom purchased by', 'Won in FTO raffle', 'prize for winning the', 'purchased MYO by', 'obtained via transformation by', 'Won in holiday raffle', \"Purchased\", \"claimed via\"]:\n",
    "        owner_count += 1\n",
    "    owner_history = \"|\" + owner_history + \"|\"\n",
    "    owner_count += len(re.findall(r\"\\|[^|]*\\s+to\\s+[^|]*\\||\\|\\s*to\\s*\\|\", owner_history))\n",
    "    return owner_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "def owner_count_from_web_response(raw_esk_record):\n",
    "    parsed_html = bs4(raw_esk_record[\"description\"])\n",
    "    owner_history = parsed_html.body.select_one('div > b:-soup-contains(\"owner history\")', class_=\"legacy-journal\")\n",
    "    try:\n",
    "        owner_history = owner_history.find_next_sibling(\"sub\")\n",
    "        owner_history = owner_history.get_text(\"|\", strip=False) \n",
    "        owner_history = re.sub('\\\\xa0', \" \", owner_history)\n",
    "    except:\n",
    "        owner_history = parsed_html.body.select_one('div > b', class_=\"legacy-journal\").parent.parent.get_text(\"|\", strip=True)\n",
    "        owner_history = re.sub('\\\\xa0', \" \", owner_history)\n",
    "        owner_history = re.sub(r'.*owner history\\s*', \"\", owner_history)\n",
    "        owner_history = re.sub(r'Esk are a closed species.*', \"\", owner_history)\n",
    "    owner_count = owner_count_from_description(owner_history)\n",
    "    if owner_count == 0:\n",
    "        owner_history = parsed_html.body.select_one('div > b', class_=\"legacy-journal\").parent.parent.parent.get_text(\"|\", strip=True)\n",
    "        owner_history = re.sub('\\\\xa0', \" \", owner_history)\n",
    "        owner_history = re.sub(r'.*owner history\\s*', \"\", owner_history)\n",
    "        owner_history = re.sub(r'Esk are a closed species.*', \"\", owner_history)\n",
    "        owner_count = owner_count_from_description(owner_history)\n",
    "    return owner_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_category(description, category, category_list):\n",
    "    try:\n",
    "        category_index = description.index(category)\n",
    "        category_list = set(category_list)\n",
    "        next_category = next((ele for ele in description[category_index + 1:] if ele in category_list), None)\n",
    "        if next_category != None:\n",
    "            try:\n",
    "                next_category_index = description.index(next_category)\n",
    "            except ValueError:\n",
    "                return 'NA'\n",
    "            category_text = \" \".join(description[category_index+1:next_category_index])    \n",
    "        else:\n",
    "            category_text = \" \".join(description[category_index+1:])\n",
    "            \n",
    "        category_text = re.sub(r'[\\.\\(]$', \"\", category_text)\n",
    "        category_text = category_text.strip()\n",
    "        return category_text\n",
    "    except ValueError:\n",
    "        return 'NA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "def esk_record_from_web_response(raw_esk_record):\n",
    "    parsed_html = bs4(raw_esk_record[\"description\"])\n",
    "    description = parsed_html.body.select_one('div > b', class_=\"legacy-journal\").parent.parent.get_text(\"|\", strip=True)\n",
    "    description = re.sub(r'ownership.*', \"\", description)\n",
    "    description = re.sub(r'\\* this pre-arpg mutation is no longer allowed for new esk', \"\", description)\n",
    "    description = re.sub(r'Esk are a closed species.*', \"\", description)\n",
    "    description = re.sub(r'\\([^\\)]*\\)', \"\", description)\n",
    "    description = re.sub('\\\\xa0', \" \", description)\n",
    "    description = re.sub(r'nature feature\\s+', \"nature features\", description)\n",
    "    description = re.sub(r'mutation(?!s)', \"mutations\", description)\n",
    "    description = re.sub(r'accessory', \"accessories\", description)\n",
    "    description = re.sub(r'elemental(?!s)', \"elementals\", description)\n",
    "    description = re.sub(r'familiar(?!s)', \"familiars\", description)\n",
    "    description = re.sub(r'enchantment(?!s)', \"enchantments\", description)\n",
    "    description = re.sub(r'blessing(?!s)', \"blessings\", description)\n",
    "    description = re.sub(r'curse(?![sd])', \"curses\", description)\n",
    "    description = re.sub(r'morphs', \"morph\", description)\n",
    "    description = re.sub('designers', \"designer\", description)\n",
    "    description = str.split(description, \"|\")\n",
    "    category_list = [\"origin\", \"nature\", \"boundary\", \"size\", \"species\", \"collection\", \"designer\", \"uncommon traits\", \"rare traits\", \"unique traits\", \"nature features\", \"mutations\", \"morph\", \"original form\", \"accessories\", \"familiars\", \"enchantments\", \"elementals\", \"TF rewards\", \"blessings\", \"curses\"]\n",
    "    for category in category_list:\n",
    "        raw_esk_record[category] = get_category(description, category, category_list)\n",
    "    raw_esk_record[\"owner count\"] = owner_count_from_web_response(raw_esk_record)\n",
    "    raw_esk_record.pop(\"size\", None)\n",
    "    raw_esk_record.pop(\"designer\", None)\n",
    "    raw_esk_record.pop(\"description\", None)\n",
    "    raw_esk_record.pop(\"TF rewards\", None)\n",
    "    raw_esk_record.pop(\"blessings\", None)\n",
    "    raw_esk_record.pop(\"curses\", None)\n",
    "    return raw_esk_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "esk_descriptions = [{\"deviationid\": esk[\"deviationid\"], \"title\": esk[\"title\"], \"description\": esk[\"description\"]} for esks in esk_metadata for esk in esks if (re.fullmatch( r\"\\d{3,4}\", esk[\"title\"]) != None)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "esk_list = []\n",
    "for esk in esk_descriptions:\n",
    "    cleaned = esk_record_from_web_response(esk)\n",
    "    if cleaned != None:\n",
    "        esk_list.append(cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(esk_list)\n",
    "deviation_id_frame = pd.DataFrame(deviation_ids)\n",
    "df = pd.merge(df, deviation_id_frame, on=\"deviationid\", how=\"inner\")\n",
    "df = df[df[\"origin\"] != \"-\"]\n",
    "df = df[df[\"origin\"] != \"???\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_biome_from_comments(deviationid):\n",
    "    global df\n",
    "    try:\n",
    "        esk_comment_metadata = requests.get(f\"https://www.deviantart.com/api/v1/oauth2/comments/deviation/{deviationid}\", \n",
    "            headers={\n",
    "                'Authorization': 'Bearer {}'.format(token)\n",
    "            },\n",
    "            params={\n",
    "                \"maxdepth\": 2\n",
    "            }).json()[\"thread\"]\n",
    "        if len(esk_comment_metadata) > 0:\n",
    "            parent_comment_id = ''\n",
    "            for comment in esk_comment_metadata:\n",
    "                if comment[\"parentid\"] == None and comment[\"user\"][\"username\"] == \"Esk-Masterlist\":\n",
    "                    parent_comment_id = comment[\"commentid\"]\n",
    "                    break\n",
    "            if len(parent_comment_id) == 0:\n",
    "                raise ValueError(\"No Esk-Masterlist comment found\")\n",
    "        else:\n",
    "             raise ValueError(\"No comments found\")\n",
    "        biome_comment = ''\n",
    "        for comment in esk_comment_metadata:\n",
    "            if comment[\"parentid\"] == parent_comment_id and comment[\"user\"][\"username\"] == \"Esk-Masterlist\":\n",
    "                biome_comment = comment[\"body\"]\n",
    "                break\n",
    "        if len(biome_comment) == 0:\n",
    "                raise ValueError(\"No reply to biome comment found\")    \n",
    "        comment_soup = bs4(biome_comment)\n",
    "        comment = comment_soup.body.find(\"img\")[\"alt\"]\n",
    "        comment = re.sub(\" by Esk-Masterlist\", \"\", comment)\n",
    "        df.loc[df[\"deviationid\"] == deviationid,\"biome\"] = comment\n",
    "        return comment\n",
    "    except ValueError as v:\n",
    "        df.loc[df[\"deviationid\"] == deviationid,\"biome\"] = \"NA\"\n",
    "        return v\n",
    "    except KeyError as k:\n",
    "        df.loc[df[\"deviationid\"] == deviationid,\"biome\"] = \"NA\"\n",
    "        return k\n",
    "    except Exception as e:\n",
    "        df.loc[df[\"deviationid\"] == deviationid,\"biome\"] = \"NA\"\n",
    "        return e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runner():\n",
    "    global df\n",
    "    threads= []\n",
    "    with ThreadPoolExecutor(max_workers=24) as executor:\n",
    "        for deviationid in df[\"deviationid\"]:\n",
    "            threads.append(executor.submit(get_biome_from_comments, deviationid))\n",
    "        \"\"\" for task in as_completed(threads):\n",
    "            print(task.result()) \"\"\" \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"esks_asgoodasitgets.csv\", \"w\") as csv_file:\n",
    "    df.to_csv(csv_file, encoding='utf-8', sep=';')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
